# Guide : SystÃ¨me de Cache Alibaba pour Ã‰conomiser sur Apify

## ğŸ¯ Objectif

Ã‰conomiser sur les coÃ»ts Apify en lanÃ§ant des batchs de scrapings et en sauvegardant les rÃ©sultats dans une base de donnÃ©es SQLite. L'API utilisera ensuite le cache au lieu de lancer de nouveaux scrapings.

## ğŸ’° Ã‰conomies

- **Sans cache** : Chaque requÃªte API = 1 scraping Apify = ~$0.05-0.10
- **Avec cache** : 1 batch = plusieurs scrapings = ~$0.50-1.00, puis toutes les requÃªtes suivantes = **GRATUIT** pendant 7 jours

**Exemple** : 
- 100 requÃªtes sans cache = $5-10
- 1 batch (10 scrapings) + 100 requÃªtes avec cache = $0.50-1.00

## ğŸ“‹ Fonctionnement

1. **Lancer un batch** : Scrape plusieurs recherches en une fois
2. **Sauvegarde automatique** : Les rÃ©sultats sont stockÃ©s dans `backend/alibaba_cache.db`
3. **Cache automatique** : L'API vÃ©rifie d'abord le cache avant d'appeler Apify
4. **Expiration** : Le cache est valide pendant 7 jours

## ğŸš€ Utilisation

### 1. Lancer un batch de scrapings

```bash
cd backend
py batch_scraper.py
```

Le script va :
- Scraper toutes les recherches dÃ©finies dans `SEARCHES`
- Sauvegarder les rÃ©sultats dans la DB
- Afficher un rÃ©sumÃ©

### 2. Personnaliser les recherches

Ã‰ditez `backend/batch_scraper.py` et modifiez la liste `SEARCHES` :

```python
SEARCHES = [
    {"type": "keyword", "valeur": "smartphone", "limit": 50},
    {"type": "keyword", "valeur": "votre-recherche", "limit": 50},
    {"type": "category", "valeur": "electronics", "limit": 50},
    # Ajoutez vos recherches ici
]
```

### 3. L'API utilise automatiquement le cache

Une fois le batch lancÃ©, toutes les requÃªtes API utiliseront le cache :

```bash
# Ces requÃªtes utiliseront le cache (gratuit)
curl http://localhost:8000/api/veille-alibaba?terme=smartphone
curl http://localhost:8000/api/veille-alibaba?categorie=electronics
```

## ğŸ“Š Gestion du Cache

### Voir les recherches en cache

Le script batch affiche automatiquement les recherches dÃ©jÃ  en cache.

### DurÃ©e de validitÃ©

- **Par dÃ©faut** : 7 jours
- Modifiable dans `backend/database.py` : `CACHE_DURATION_DAYS`

### Nettoyage automatique

Le cache expirÃ© est automatiquement nettoyÃ© :
- Au lancement d'un nouveau batch
- Vous pouvez aussi le nettoyer manuellement (voir code dans `database.py`)

## ğŸ”§ Configuration

### Base de donnÃ©es

- **Fichier** : `backend/alibaba_cache.db` (SQLite)
- **Tables** :
  - `produits_alibaba` : Stocke les produits
  - `recherches_alibaba` : Stocke les mÃ©tadonnÃ©es des recherches

### DurÃ©e du cache

Modifiez dans `backend/database.py` :

```python
CACHE_DURATION_DAYS = 7  # Changez ici (en jours)
```

## ğŸ“ Exemple Complet

### Ã‰tape 1 : Lancer un batch

```bash
cd backend
py batch_scraper.py
```

**Sortie** :
```
ğŸš€ BATCH SCRAPING ALIBABA
============================================================

ğŸ§¹ Nettoyage du cache expirÃ©...

ğŸ“¦ Recherches dÃ©jÃ  en cache: 0

[1/8] Scraping: keyword=smartphone (limit: 50)
------------------------------------------------------------
ğŸš€ Lancement du scraper Apify pour Alibaba...
âœ… Run Apify lancÃ©: abc123
â³ Attente des rÃ©sultats...
âœ… Scraping terminÃ© avec succÃ¨s
ğŸ“¦ 50 rÃ©sultats rÃ©cupÃ©rÃ©s depuis Apify
âœ… 50 produits convertis et prÃªts
âœ… 50 produits sauvegardÃ©s dans la DB (recherche: keyword=smartphone)
âœ… 50 produits scrapÃ©s et sauvegardÃ©s

...

ğŸ“Š RÃ‰SUMÃ‰
============================================================
âœ… Produits scrapÃ©s: 400
ğŸ’¾ Produits sauvegardÃ©s: 400
âŒ Erreurs: 0

ğŸ’¡ Les produits sont maintenant en cache dans la DB
ğŸ’¡ L'API utilisera le cache au lieu de lancer de nouveaux scrapings
```

### Ã‰tape 2 : Utiliser l'API (gratuit maintenant)

```bash
# Ces requÃªtes utilisent le cache (gratuit)
curl http://localhost:8000/api/veille-alibaba?terme=smartphone
curl http://localhost:8000/api/veille-alibaba?terme=laptop
```

## âš ï¸ Notes Importantes

1. **Premier lancement** : Le batch peut prendre 10-20 minutes (selon le nombre de recherches)
2. **CoÃ»ts Apify** : Un batch de 10 recherches = ~$0.50-1.00
3. **Cache expirÃ©** : AprÃ¨s 7 jours, il faudra relancer un batch
4. **Nouvelles recherches** : Si vous cherchez quelque chose qui n'est pas en cache, Apify sera appelÃ© (et sauvegardÃ© automatiquement)

## ğŸ¯ StratÃ©gie RecommandÃ©e

1. **Lancer un batch hebdomadaire** avec vos recherches principales
2. **Ajouter des recherches** au fur et Ã  mesure dans le batch
3. **Surveiller les coÃ»ts** Apify dans votre console
4. **Ajuster la durÃ©e du cache** selon vos besoins

## ğŸ” VÃ©rifier le Cache

Pour voir ce qui est en cache, vous pouvez utiliser Python :

```python
from database import get_all_cached_searches
recherches = get_all_cached_searches()
for r in recherches:
    print(f"{r['type']}={r['valeur']}: {r['nombre_produits']} produits")
```

## ğŸ’¡ Astuces

- **Lancez le batch la nuit** pour Ã©viter d'utiliser votre quota pendant la journÃ©e
- **Groupez les recherches similaires** pour optimiser
- **Augmentez le `limit`** dans le batch pour avoir plus de produits en cache
- **RÃ©duisez `CACHE_DURATION_DAYS`** si vous voulez des donnÃ©es plus fraÃ®ches

